{
  
    
        "post0": {
            "title": "Kornia 0.5.5 release",
            "content": "Kornia team is happy to announce the release for v0.5.5. . Support for PyTorch 1.9.0 | Interface for Stereo Camera manipulation | Random selection for the augmentation containers | Bug fixes | . Checkout the release notes to discover more about our contributors https://github.com/kornia/kornia/releases/tag/0.5.5 . In addition, we are revamping our online documentation by adding as much as visual examples to each functionality. . Visit our documentation here: https://kornia.readthedocs.io/en/latest/enhance.html . üëâ Feel free to reach us for collaborations . Visit our website üöÄ www.kornia.org üöÄ Give us a star in Github ‚≠êÔ∏è https://github.com/kornia/kornia/stargazers ‚≠êÔ∏è Follow us in Twitter üê¶ https://twitter.com/kornia_foss üê¶ Donate (@opencollective) üôè https://opencollective.com/kornia üôè . #computervision #opensource #deeplearning #pytorch .",
            "url": "/kornia-blog/release/2021/06/27/kornia-release-055.html",
            "relUrl": "/release/2021/06/27/kornia-release-055.html",
            "date": " ‚Ä¢ Jun 27, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Roadmap Kornia v0.6.0 !",
            "content": "Roadmap Kornia v0.6.0 announcement . . Hello KORNIANS ! . After the release of Kornia v0.5.0, we are pleased to announce that we are striking back with new ideas for future releases. . For this reason, we have published our public Kornia v0.6.0 [ROADMAP] . In the upcoming release we will target the following high level features: . Improve kornia.augmentations and refactor the backend pipeline to support Torchscript. | Improve kornia.color module adding more functionality with losses. | Add kornia.nn module to wrap functionals as torch modules. | . Feel free to volunteer yourself if you are interested in trying out some items (they do not have to be on the list). . Please, take also a read on the CONTRIBUTING notes. . Stay tuned and have a happy coding day ! :sunglasses: . The Kornia team .",
            "url": "/kornia-blog/community/announcement/2021/04/06/kornia-roadmap-v060.html",
            "relUrl": "/community/announcement/2021/04/06/kornia-roadmap-v060.html",
            "date": " ‚Ä¢ Apr 6, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Kornia v0.5.0 release",
            "content": "In this release we have focus in bringing more classic Computer Vision functionalities to the PyTorch ecosystem, like morphological operators and more diversity with Deep Local Descriptors, color conversions and drawing functions. In addition, we have worked towards improving the integration with TPU and better support with Torchscript. . Morphological Operators . As a highlight we include a kornia.morphology that implements several functionalities to work with morphological operators on high-dimensional tensors and differentiability. Contributed by @Juclique . Morphology implements the following methods: dilation, erosion, open, close, close, gradient, top_hat and black_hat. . from kornia import morphology as morph dilated_image = morph.dilation(tensor, kernel) # Dilation plot_morph_image(dilated_image) # Plot . . See a full tutorial here: https://github.com/kornia/tutorials/blob/master/source/morphology_101.ipynb . Deep Descriptors . We have added a set of local feature-related models: MKDDescriptor #841 by implemented and ported to kornia by @manyids2; also we ported TFeat, AffNet, OriNet from authors repos #846. . Here is notebook, showing the usage and benefits of new features. We also show how to seamlessly integrate kornia and opencv code via new conversion library kornia_moons. . Also: exposed set_laf_orientation function #869 . . Video Augmentations . We include a new operator to perform augmentations with videos VideoSequential. The module is based in nn.Sequential and has the ability to concatenate our existing kornia.augmentations for multi-dimensional video tensors. Contributed by @shijianjian . import kornia import torchvision clip, _, _ = torchvision.io.read_video(&quot;drop.avi&quot;) clip = clip.permute(3, 0, 1, 2)[None] / 255. # To BCTHW input = torch.randn(2, 3, 1, 5, 6).repeat(1, 1, 4, 1, 1) aug_list = VideoSequential( kornia.augmentation.ColorJitter(0.1, 0.1, 0.1, 0.1, p=1.0), kornia.augmentation.RandomAffine(360, p=1.0), data_format=&quot;BTCHW&quot;, same_on_frame=False) ) out = aug(input) . . See a full example in the following Colab: https://colab.research.google.com/drive/12dmHNkvEQrG-PHElbCXT9FgCr_aAGQSI?usp=sharing . Draw functions . We include an experimental functionality draw_rectangle implemented in pure torch.tensor. Contributed by @mmathew23 . rects = torch.tensor([[[110., 50., 310., 275.], [325., 100., 435., 275.]]]) color = torch.tensor([255., 0., 0.]) x_out = K.utils.draw_rectangle(x_rgb, rects, color) . . See full example here: https://colab.research.google.com/drive/1me_DxgMvsHIheLh-Pao7rmrsafKO5Lg3?usp=sharing . More user contrib . binary_focal_loss_with_logits #830 by @xen0f0n | rgb_to_lab #823 by @cceyda | GaussianBlur augmentation #773 by @ZhiyuanChen | get_gaussian_erf_kernel1d, get_gaussian_discrete #736 by @wyli | equalize_clahe #895 by @lferraz | blur_pool2d #894 by @shijianjian | get_tps_transform, warp_points_tps, warp_image_tps #897 by @catalys1 | elastic_transform_2d #853 by @IssamLaradji @edgarriba | . Infrastructure . Update CI to pytorch 1.7.x and 1.8.0 @edgarriba | Improve testing matrix with different versions | TPU support @edgarriba @shijianjian | Better JIT support @edgarriba @shijianjian @ducha-aiki | Improved and test docs @shijianjian @edgarriba | . Deprecations . Deprecated kornia.geometry.warp module. DepthWarper is now in kornia.geometry.depth | HomographyWarper and related functions are now inside kornia.geometry.transform. | . | Deprecated kornia.contrib module. max_pool_blurd2d is now in kornia.filters | . | Dropped support of Pytorch 1.5.1 #854 | . Warp and Crop . We refactored the interface of the functions warp_perspective, warp_affine, center_crop, crop_and_resize and crop_by_boxes in order to expose to the user the needed parameters by grid_sample [mode, padding_mode, align_corners]. #896 . The param align_corners has been set by default to None that maps to True in case the user does not specify. This comes from the motivation to match the behavior of the warping functions with OpenCV. . Example of warp_perspective: . def warp_perspective(src: torch.Tensor, M: torch.Tensor, dsize: Tuple[int, int], mode: str = &#39;bilinear&#39;, padding_mode: str = &#39;zeros&#39;, align_corners: Optional[bool] = None) -&gt; torch.Tensor: . Please review the full release notes here: https://github.com/kornia/kornia/blob/master/CHANGELOG.md . Thanks to all our contributors !!! :sunglasses: .",
            "url": "/kornia-blog/release/2021/03/17/kornia-release-v050.html",
            "relUrl": "/release/2021/03/17/kornia-release-v050.html",
            "date": " ‚Ä¢ Mar 17, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Kornia v0.4.1 release",
            "content": "Kornia team is happy to announce the release for v0.4.1. . We include new features for 3D augmentations: . RandomCrop3D | CenterCrop3D | RandomMotionBlur3D | RandomEqualize3D | . Few more core functionalities to work on 3D volumetric tensors: . warp_affine3d | warp_perspective3d | get_perspective_transform3d | crop_by_boxes3d | motion_blur3d | equalize3d | warp_grid3d | . Details changes . Added . Update docs for get_affine_matrix2d and get_affine_matrix3d (#618) | Added docs for solarize, posterize, sharpness, equalize (#623) | Added tensor device conversion for solarize params (#624) | Added rescale functional and transformation (#631) | Added Mixup data augmentation (#609) | Added equalize3d (#639) | Added decompose 3x4projection matrix (#650) | Added normalize_min_max functionality (#684) | Added random equalize3d (#653) | Added 3D motion blur (#713) | Added 3D volumetric crop implementation (#689) warp_affine3d | warp_perspective3d | get_perspective_transform3d | crop_by_boxes3d | warp_grid3d | . | . Changed . Replace convolution with unfold in contrib.extract_tensor_patches (#626) | Updates Affine scale with non-isotropic values (#646) | Enabled param p for each augmentation (#664) | Enabled RandomResizedCrop batch mode when same_on_batch=False (#683) | Increase speed of transform_points (#687) | Improves find_homography_dlt performance improvement and weights params made optional (#690) | Enable variable side resizing in kornia.resize (#628) | Added Affine transformation as nn.Module (#630) | Accelerate augmentations (#708) | . Fixed . Fixed error in normal_transform_pixel3d (#621) | Fixed pipelining multiple augmentations return wrong transformation matrix (#645)(645) | Fixed flipping returns wrong transformation matrices (#648) | Fixed 3d augmentations return wrong transformation matrix (#665) | Fix the SOSNet loading bug (#668) | Fix/random perspective returns wrong transformation matrix (#667) | Fixes Zca inverse transform (#695) | Fixes Affine scale bug (#714) | . Removed . Removed warp_projective (#689) | . Contributors . @gaurav104 @shijianjian @mshalvagal @pmeier @ducha-aiki @qxcv @FGeri @vribeiro1 @ChetanPatil28 @alopezgit @jatentaki @dkoguciuk @ceroytres @ag14774 . . Please, do not hesitate to check the release notes on GitHub to learn about the new library features and get more details. . Have a happy coding day :sunglasses: . The Kornia team .",
            "url": "/kornia-blog/release/2020/10/20/kornia-release-v041.html",
            "relUrl": "/release/2020/10/20/kornia-release-v041.html",
            "date": " ‚Ä¢ Oct 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Hello World !",
            "content": "‚ÄúA long time ago in a galaxy far, far away‚Ä¶.‚Äù . . ‚ÄúIt is a period to backprop gradients ! Rebel researchers, striking from a hidden remote server, have won their first victory against the Classical Computer Vision Empire. During this years, Rebel hackers managed to learn the intels of Empire‚Äôs ultimate weapon, the OPENCV library, a technology that combined with enough ability with PYTORCH can change the Computer Vision paradigm. . Backed up by the Open Source Community, the KORNIANS from their headquartes the PLANET KORNIA, released a first version of a Differentiable Computer Vision Library for PyTorch that can save the Computer Vision community to get stuck in local minima‚Ä¶‚Äù . . Hello KORNIANS ! . This is the first post in the Kornia blog to welcome you in our community. We will be using this place for announcements on the library, releases and other cool stuff. . Stay tuned and have a happy coding day ! :sunglasses: . The Kornia team .",
            "url": "/kornia-blog/community/announcement/2020/10/02/hello-world.html",
            "relUrl": "/community/announcement/2020/10/02/hello-world.html",
            "date": " ‚Ä¢ Oct 2, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Kornia v0.4.0 release",
            "content": "Kornia team is happy to announce the release for v0.4.0. . We are releasing a new version for Kornia that includes different functionalities to work with 3D augmentations and volumetric data, local features matching, homographies and epipolar geometry. . In short, we list the following new features: . Support for PyTorch v1.6.0. | Local descriptors matching, homography and epipolar geometry API. | 3D augmentations and low-level API to work with volumetric data. | . Local features matching . We include an kornia.feature.matching API to perform local descriptors matching such classical and derived version of the nearest neighbor (NN). . . import torch import kornia as K desc1 = torch.rand(2500, 128) desc2 = torch.rand(2500, 128) dists, idxs = K.feature.matching.match_nn(desc1, desc2) # 2500 / 2500x2 . Homography and epipolar geometry . We also introduce kornia.geometry.homography including different functionalities to work with homographies and differentiable estimators based on the DLT formulation and the iteratively-reweighted least squares (IRWLS). . . import torch import kornia as K pts1 = torch.rand(1, 8, 2) pts2 = torch.rand(1, 8, 2) H = K.find_homography_dlt(pts1, pts2, weights=torch.rand(1, 8)) # 1x3x3 . In addition, we have ported some of the existing algorithms from opencv.sfm to PyTorch under kornia.geometry.epipolar that includes different functionalities to work with Fundamental, Essential or Projection matrices, and Triangulation methods useful for Structure from Motion problems. . 3D augmentations and volumetric . We expand the kornia.augmentaion with a series of operators to perform 3D augmentations for volumetric data. . . In this release, we include the following first set of geometric 3D augmentations methods: . RandomDepthicalFlip3D (along depth axis) | RandomVerticalFlip3D (along height axis) | RandomHorizontalFlip3D (along width axis) | RandomRotation3D | RandomAffine3D | . The API for 3D augmentation work same as with 2D image augmentations: . import torch import kornia as K x = torch.eye(3).repeat(3, 1, 1) aug = K.augmentation.RandomVerticalFlip3D(p=1.0) print(aug(x)) tensor([[[[[0., 0., 1.], [0., 1., 0.], [1., 0., 0.]], &lt;BLANKLINE&gt; [[0., 0., 1.], [0., 1., 0.], [1., 0., 0.]], &lt;BLANKLINE&gt; [[0., 0., 1.], [0., 1., 0.], [1., 0., 0.]]]]]) . Finally, we also introduce a low level API to perform 4D features transformations kornia.warp_projective and extending the filtering operators to support 3D kernels kornia.filter3D. . More 2d operators . We expand as well the list of the 2D image augmentations based on the paper AutoAugment: Learning Augmentation Policies from Data. . Solarize | Posterize | Sharpness | Equalize | RandomSolarize | RandomPosterize | RandomShaprness | RandomEqualize | . . Please, do not hesitate to check the release notes on GitHub to learn about the new library features and get more details. . Have a happy coding day :sunglasses: . The Kornia team .",
            "url": "/kornia-blog/release/2020/08/07/kornia-release-v040.html",
            "relUrl": "/release/2020/08/07/kornia-release-v040.html",
            "date": " ‚Ä¢ Aug 7, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Kornia 0.3.0 release",
            "content": "Today we released 0.3.0 which aligns with PyTorch releases cycle and includes: . Full support to PyTorch v1.5. | Semi-automated GPU tests coverage. | Documentation has been reorganized [docs]. | Data augmentation API compatible with torchvision v0.6.0. | Well integration with ecosystem e.g. Pytorch-Lightning. | . For more detailed changes check out v0.2.1 and v0.2.2. . Highlights . Data Augmentation . We provide kornia.augmentation a high-level framework that implements kornia-core functionalities and is fully compatible with torchvision supporting batched mode, multi device cpu, gpu, and xla/tpu (comming), auto differentiable and able to retrieve (and chain) applied geometric transforms. To check how to reproduce torchvision in kornia refer to this Colab: Kornia vs. Torchvision @shijianjian . import kornia as K import torchvision as T # kornia transform_fcn = torch.nn.Sequential( K.augmentation.RandomAffine( [-45., 45.], [0., 0.5], [0.5, 1.5], [0., 0.5], return_transform=True), K.color.Normalize(0.1307, 0.3081), ) # torchvision transform_fcn = T.transforms.Compose([ T.transforms.RandomAffine( [-45., 45.], [0., 0.5], [0.5, 1.5], [0., 0.5]), T.transforms.ToTensor(), T.transforms.Normalize((0.1307,), (0.3081,)), ]) . Ecosystem compatibility . Kornia has been designed to be very flexible in order to be integrated in other existing frameworks. See the example below about how easy you can define a custom data augmentation pipeline to later be integrated into any training framework such as Pytorch-Lighting. We provide examples in [here] and [here]. . class DataAugmentatonPipeline(nn.Module): &quot;&quot;&quot;Module to perform data augmentation using Kornia on torch tensors.&quot;&quot;&quot; def __init__(self, apply_color_jitter: bool = False) -&gt; None: super().__init__() self._apply_color_jitter = apply_color_jitter self._max_val: float = 1024. self.transforms = nn.Sequential( K.augmentation.Normalize(0., self._max_val), K.augmentation.RandomHorizontalFlip(p=0.5) ) self.jitter = K.augmentation.ColorJitter(0.5, 0.5, 0.5, 0.5) @torch.no_grad() # disable gradients for effiency def forward(self, x: torch.Tensor) -&gt; torch.Tensor: x_out = self.transforms(x) if self._apply_color_jitter: x_out = self.jitter(x_out) return x_out . GPU tests . Now easy to run GPU tests with pytest --typetest cuda . . Please, do not hesitate to check the release notes on GitHub to learn about the new library features and get more details. . Have a happy coding day :sunglasses: . The Kornia team .",
            "url": "/kornia-blog/release/2020/04/27/kornia-release-v030.html",
            "relUrl": "/release/2020/04/27/kornia-release-v030.html",
            "date": " ‚Ä¢ Apr 27, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Kornia 0.2.1 release",
            "content": "In this release we support compatibility between kornia.augmentation and torchvision.transforms. . We now support all the same existing operations with torch.Tensor in the GPU with extra features such as returning for each operator the transformation matrix generated to produce such transformation. . import kornia as K import torchvision as T # kornia transform_fcn = torch.nn.Sequential( K.augmentation.RandomAffine( [-45., 45.], [0., 0.5], [0.5, 1.5], [0., 0.5], return_transform=True), K.color.Normalize(0.1307, 0.3081), ) # torchvision transform_fcn = T.transforms.Compose([ T.transforms.RandomAffine( [-45., 45.], [0., 0.5], [0.5, 1.5], [0., 0.5]), T.transforms.ToTensor(), T.transforms.Normalize((0.1307,), (0.3081,)), ]) . Check the online documentations with the updated API [DOCS] . Check this Google Colab to see how to reproduce same results [Colab] . kornia.augmentation as a framework . In addition, we have re-designed kornia.augmentation such in a way that users can easily contribute with more operators, or just use it as a framework to create their custom operators. . Each of the kornia.augmentation modules inherit from AugmentationBase and one can easily define a new operator by creating a subclass and overriding a couple of methods. . Let‚Äôs take a look at a custom MyRandomRotation. The class inherits from AugmentationBase making it a nn.Module so that can be stacked in a nn.Sequential to compute chained transformations. . To implement a new functionality two things needed: override get_params and apply. . The get_params receives the shape of the input tensor and returns a dictionary with the parameters to use in the apply function. . The apply function receives as input a tensor and the dictionary defined in get_params and returns a tuple with the transformed input and the transformation applied to it. . class MyRandomRotation(AugmentationBase): def __init__(self, angle: float, return_transform: bool = True) -&gt; None: super(MyRandomRotation, self).__init__(self.apply, return_transform) self.angle = angle def get_params(self, batch_shape: torch.Size) -&gt; Dict[str, torch.Tensor]: angles_rad torch.Tensor = torch.rand(batch_shape) * K.pi angles_deg = kornia.rad2deg(angles_rad) * self.angle return dict(angles=angles_deg) def apply(self, input: torch.Tensor, params: Dict[str, torch.Tensor]): # compute transformation angles: torch.Tensor = params[&#39;angles&#39;].type_as(input) center = torch.tensor([[W / 2, H / 2]]).type_as(input) transform = K.get_rotation_matrix2d( center, angles, torch.ones_like(angles)) # apply transformation output = K.warp_affine(input, transform, (H, W)) return (output, transform) # how to use it # load an image and cast to tensor img1: torch.Tensor = imread(...) # BxDxHxW # instantiate and apply the transform aug = MyRandomRotation(45., return_transformation=True) img2, transform = aug(img1) # BxDxHxW - Bx3x3 . . Please, do not hesitate to check the release notes on GitHub to learn about the new library features and get more details. . Have a happy coding day :sunglasses: . The Kornia team .",
            "url": "/kornia-blog/release/2020/04/21/kornia-release-v021.html",
            "relUrl": "/release/2020/04/21/kornia-release-v021.html",
            "date": " ‚Ä¢ Apr 21, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Kornia 0.2.0 release",
            "content": "Kornia v0.2.0 release is now available. . The release contains over 50 commits and updates support to PyTorch 1.4. This is the result of a huge effort in the desing of the new data augmentation module, improvements in the set of the color space conversion algorithms and a refactor of the testing framework that allows to test the library using the cuda backend. . Data Augmentation API . From this point forward, we will give support to the new data augmentation API. The kornia.augmentation module mimics the best of the existing data augmentation frameworks such torchvision or albumentations all re-implemented assuming as input torch.Tensor data structures that will allowing to run the standard transformations (geometric and color) in batch mode in the GPU and backprop through it. . In addition, a very interesting feature we are very proud to include, is the ability to return the transformation matrix for each of the transform which will make easier to concatenate and optimize the transforms process. . A quick overview of its usage: . import torch import kornia input: torch.Tensor = load_tensor_data(....) # BxCxHxW transforms = torch.nn.Sequential( kornia.augmentation.RandomGrayscale(), kornia.augmentation.RandomAffine(degrees=(-15, 15)), ) out: torch.Tensor = transforms(input) # CPU out: torch.Tensor = transforms(input.cuda()) # GPU # same returning the transformation matrix transforms = torch.nn.Sequential( kornia.augmentation.RandomGrayscale(return_transformation=True), kornia.augmentation.RandomAffine(degrees=(-15, 15), return_transformation=True), ) out, transform = transforms(input) # BxCxHxW , Bx3x3 . GPU Test . We have refactored our testing framework and we can now easily integrate GPU tests within our library. At this moment, this features is only available to run locally but very soon we will integrate with CircleCI and AWS infrastructure so that we can automate the process. . From root one just have to run: make test-gpu . Tests look like this: . import torch from test.common import device def test_rgb_to_grayscale(self, device): channels, height, width = 3, 4, 5 img = torch.ones(channels, height, width).to(device) assert kornia.rgb_to_grayscale(img).shape == (1, height, width) . . Please, do not hesitate to check the release notes on GitHub to learn about the new library features and get more details. . Have a happy coding day :sunglasses: . The Kornia team .",
            "url": "/kornia-blog/release/2020/01/27/kornia-release-v020.html",
            "relUrl": "/release/2020/01/27/kornia-release-v020.html",
            "date": " ‚Ä¢ Jan 27, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Kornia BCN Hackathon 2019",
            "content": ". The Computer Vision Center is hosting the Kornia Hackathon 2019 on December 14th as a satellite event of the Deep Learning Symposium Barcelona. The aim of the event is a hands-on in differentiable computer vision with PyTorch session with two of the Kornia project leaders, Edgar Riba and Dmytro Mishkin. . Edgar Riba is one of the main promoters of Kornia, member of the Open Source Vision foundation and OpenCV technical committee member. He is currently finishing his PhD at the UPC on ‚ÄòGeometric Computer Vision and Local Features detection‚Äô. On the other hand, Dmytro Mishkin, also a Kornia promoter, is currently a PhD student at the Centre for Machine Perception of the Czech Technical University in Prague. Furthermore, Dmytro is the ex-CTO of Clear Research, the co-founder of the Ukrainian Research Group ‚ÄúSzkocka‚Äù, co-founder of the Eastern European Computer Vision Conference (EECVC) and Kaggle Master. . The Hackathon will start at 10.00 and finish at 18.00. The full program will be released soon. The Hackathon is sponsored by OpenCV.org, the OSVF.org, the Computer Vision Center, PyTorch and AWS. All twitter promotion will be available under the hashtag #HackathonKornia19. . Technical requirements . A solid knowledge of PyTorch, Computer Vision and Deep Learning would be ideal. All the attendees should bring their own laptop. Internet connection will be provided. . Registration . Registration is open until December 12th here: https://forms.gle/xRGw1k6njDzthRkB6 . About Kornia . Kornia is an open source Computer Vision library for PyTorch. More information on the projecte here: https://kornia.org . Any queries must be directed to edgar.riba@osvf.org .",
            "url": "/kornia-blog/community/2019/12/14/kornia-hackathon-2019.html",
            "relUrl": "/community/2019/12/14/kornia-hackathon-2019.html",
            "date": " ‚Ä¢ Dec 14, 2019"
        }
        
    
  
    
        ,"post10": {
            "title": "Kornia 0.1.4 release",
            "content": "We have just released Kornia: a differentiable computer vision library for PyTorch. . It consists of a set of routines and differentiable modules to solve generic computer vision problems. At its core, the package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions. . Inspired by OpenCV, this library is composed by a subset of packages containing operators that can be inserted within neural networks to train models to perform image transformations, epipolar geometry, depth estimation, and low level image processing such as filtering and edge detection that operate directly on tensors. . It has over 300 commits and majorly refactors the whole library including over than 100 functions to solve generic Computer Vision problems. . Highlights . Version 0.1.4 includes a reorganization of the internal API grouping functionalities that consists of the following components: . kornia | a Differentiable Computer Vision library like OpenCV, with strong GPU support. | . | kornia.color | a set of routines to perform color space conversions. | . | kornia.contrib | a compilation of user contrib and experimental operators. | . | kornia.feature | a module to perform local feature detection. | . | kornia.filters | a module to perform image filtering and edge detection. | . | kornia.geometry | a geometric computer vision library to perform image transformations, 3D linear algebra and conversions using differen camera models. | . | kornia.losses | a stack of loss functions to solve different vision tasks. | . | kornia.utils | image to tensor utilities and metrics for vision problems. | . | . Big contribution in kornia.features: . Implemented anti-aliased local patch extraction. | Implemented classical local features cornerness functions: Harris, Hessian, Good Features To Track. | Implemented basic functions for work with local affine features and their patches. | Implemented convolutional soft argmax 2d and 3d operators for differentable non-maxima suppression. | implemented second moment matrix affine shape estimation, dominant gradient orientation and SIFT patch descriptor. | . . Please, do not hesitate to check the release notes on GitHub to learn about the new library features and get more details. . Have a happy coding day :sunglasses: . The Kornia team .",
            "url": "/kornia-blog/release/2019/10/27/kornia-release-v014.html",
            "relUrl": "/release/2019/10/27/kornia-release-v014.html",
            "date": " ‚Ä¢ Oct 27, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Learn more about us in www.kornia.org . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "/kornia-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "/kornia-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}